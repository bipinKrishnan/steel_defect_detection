{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the image to batches to solve memory error\n",
    "path_csv = '/home/abhigith/Desktop/steel_defect_dataset/train.csv'   #complete path to csv data of images \n",
    "path_image_train = '/home/abhigith/Desktop/steel_defect_dataset/batch_images/'  #complete path to training images\n",
    "data_csv = pd.read_csv(path_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_HEIGHT = 256\n",
    "IMG_WIDTH = 1600\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_enc = data_csv['EncodedPixels']\n",
    "data_img_id = list(data_csv['ImageId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7095,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_enc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img = next(os.walk(path_image_train))[2]    #walk through all images in the path\n",
    "train_img.index('0a1cade03.jpg')                  #to get the index of an image id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.zeros((len(train_img), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "y_train = np.zeros((len(train_img), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
    "img_with_mask = np.zeros((len(train_img), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle2mask(rle, imgshape):\n",
    "    #width & height of steel image\n",
    "    width = imgshape[0]    \n",
    "    height= imgshape[1]\n",
    "    \n",
    "    #flatttened empty array with size of input image\n",
    "    mask= np.zeros( width*height ).astype(np.uint8)\n",
    "    #convert all elements of encoded image pixels to int values\n",
    "    array = np.asarray([int(x) for x in rle.split()])\n",
    "    \n",
    "    #splitting the encoded pixels\n",
    "    #every odd index of encoded array is the start pixel &\n",
    "    #every even index of encoded array is the length of the mask from start\n",
    "    starts = array[0::2]\n",
    "    lengths = array[1::2]\n",
    "    \n",
    "    #expanding the encoded pixel\n",
    "    #current_position = 0\n",
    "    for index, start in enumerate(starts):\n",
    "        mask[int(start):int(start+lengths[index])] = 255\n",
    "        #current_position += lengths[index]\n",
    "    \n",
    "    #numpy operations to bring the shape of mask suitable to image\n",
    "    return np.flipud( np.rot90( mask.reshape(height,width), k=1 ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 86.33it/s]\n"
     ]
    }
   ],
   "source": [
    "for i, img_id in tqdm(enumerate(train_img), total=len(train_img)):\n",
    "    path = path_image_train + img_id\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_resize = np.resize(img, (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS))\n",
    "    x_train[i] = img_resize     #store all the train images as numpy arrays for training\n",
    "    \n",
    "    #check whether an image has corresponding mask in the csv data or not\n",
    "    if img_id in data_img_id:\n",
    "        idx = data_img_id.index(img_id)\n",
    "        img_resize_1 = np.resize(img, (IMG_HEIGHT,IMG_WIDTH,1))\n",
    "        y_train[i] = rle2mask(data_enc[idx], img_resize_1.shape)   #store all the masks as numpy arrays for training\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig=plt.figure(figsize=(20,100))\n",
    "columns = 2\n",
    "rows = 50\n",
    "\n",
    "for i in range(1, 10):\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    img = cv2.imread( path_image_train+fn )\n",
    "    mask = rle2mask( data_csv['EncodedPixels'].iloc[i], img.shape  )\n",
    "    img[mask==1,0] = 255\n",
    "    \n",
    "    plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert numpy array to image\n",
    "from PIL import Image\n",
    "y = Image.fromarray(y_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = cv2.imread(path_image_train+'0abfbfc69.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f885e91b710>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
